Probability {data-navmenu="Probability"}
=====================================

Column {.tabset}
-------------------------------------------------

### Introduction

<h4> Probability</h4>

Probability theory provides a mathematical model for the study of randomness and uncertainty. 
<p>
Many important decisions, whether from business, government, science, recreation or even one's personal life must be made with incomplete information or some degree of uncertainty. Hence, a formalized study of uncertain or random outcomes occupies an important role in modern society. In situations where one of any number of possible outcomes may occur, the mathematical model of probability theory offers methods for quantifying the likelihoods associated with those outcomes. 
<p>
Probability also provides tools which allow us to move beyond simply describing the information contained within a set of data (descriptive statistics) to actually inferring further information from that data (inferential statistics). 

Many of the early attempts to model likelihood arose from games of chance. 

### Basics of Probability

#### Experiments

An experiment is any action or process whose outcome is subject to uncertainty or randomness.

Here the term experiment is used in a wider sense than its usual connotation with controlled laboratory situations. Further clarification on experiments will be given later, but for now the following examples of experiments will suffice:

* observing whether or not a commercial product is defective.
* tossing a coin one or more times or selecting a card from a card deck.
* conducting a survey.
* measuring the wind speed or rainfall in a particular area.

Assuming that an experiment can be repeated under identical conditions, then each repetition of an experiment is called a ***trial***.

#### Sample Space

* The sample space, ${\displaystyle \Omega }$, is the non-empty set whose elements are all possible outcomes of an experiment. 
* Without an assignment of a sample space and without knowing its size, no conclusions could be made about the probabilities of outcomes, or collections of outcomes. 
* It is common to refer to a sample space by the labels ${\displaystyle S}$, ${\displaystyle \Omega }$ , or ${\displaystyle U}$ (for "universal set"). 
* An Outcome ${\displaystyle \Omega }$  may be a state of nature, a possibility, an experimental result and the like. 
* Any instance or execution of a real-world situation modeled by a probability space must produce exactly one outcome.
* If outcomes of different trials of an experiment differ in any way that matters, they are considered distinct outcomes. 
* Which differences matter depends on the kind of analysis we wish to perform: This leads to different choices of a sample space. 
* A common example consists of a random experiment involving a single coin toss. 
* Here, it seems appropriate to define the sample space as the set 

${\displaystyle \Omega }=\{{\text{H}},{\text{T}}\}}{\displaystyle \Omega =\{{\text{H}},{\text{T}}\}}.$

#### Events
Since individual outcomes might be of little practical use, more complex events are used to characterize groups of outcomes. 
<p>
An event is any subset of zero or more outcomes contained in a given sample space. A simple event consists of exactly one outcome and a compound event consists of more than one outcome. For example, when tossing a single coin ${\displaystyle \Omega =\{{\text{H}},{\text{T}}\}}$, possible events are ${\displaystyle \{\}}\{\}, {\displaystyle \{H\}}{\displaystyle \{H\}}, {\displaystyle \{T\}}{\displaystyle \{T\}}$, and ${\displaystyle \{H,T\}}{\displaystyle \{H,T\}}$. 
<p>

* The collection of all such events is a Ïƒ-algebra ${\mathcal {F}}$. Intuitively, the probability of each of these sets is the chance that one of the events in the set will happen; ${\displaystyle P(\{{\text{H}}\})}$ is the chance of tossing a head, ${\displaystyle P(\{{\text{H}},{\text{T}}\})}$ is the chance of the coin landing either heads or tails, and {\displaystyle P(\{\})}{\displaystyle P(\{\})} is the probability of the coin landing neither heads nor tails, etc. 
* An event is said to have happened or occurred during an experiment when the outcome of the experiment is an element of the event. 
<p>
* Since the same outcome may be a member of many events, it is possible for many events to have happened given a single outcome. 

<p>

For example, when the trial consists of throwing two dice, the set of all outcomes with a sum of 7 pips may constitute an event, whereas outcomes with an odd number of pips may constitute another event. 
<p>
* If the outcome is the element of the elementary event of two pips on the first die and five on the second, then both of the events, "7 pips" and "odd number of pips", are said to have occurred. Modeling events as sets of outcomes in a sample space $\Omega$  allows us to leverage all of the regular set operations:
<p>
Given two events $A$ and $B$:

* The null subset ${\displaystyle \emptyset }$ in a sample space $\Omega$  is called an impossible event.
* The union of two events ${\displaystyle A\cup B}$ consists of all outcomes that are in $A$ or in $B$ or in both,
* The intersection {\displaystyle A\cap B}A\cap B consists of all outcomes that are both in $A$ and $B$.
* The complement ${\displaystyle A^{c}}$ of an event $A$ in a sample space $\Omega$  consists of all outcomes not in $A$, but in $\Omega$ , i.e. ${\displaystyle A\cup A^{c}=\Omega }$.

Rules of Probability {data-navmenu="Probability"}
=====================================

Column {.tabset}
-------------------------------------------------


### Rules of Probability


What Are the Rules of Probability in Math?

<p><strong>1. Addition Rule</strong></p>

<p>Whenever an event is the union of two other events, say A and B, then \(P(A \text { or } B)=P(A)+P(B)-P(A \cap B)\)</p>

<p>\(\mathrm{P}(\mathrm{A} \cup \mathrm{B})=\mathrm{P}(\mathrm{A})+\mathrm{P}(\mathrm{B})-\mathrm{P}(\mathrm{A} \cap \mathrm{B})\)</p>

<p><strong>2. Complementary Rule</strong></p>

<p>Whenever an event is the complement of another event, specifically, if A is an event, then P(not A)=1&minus;P(A) or P(A&#39;) = 1 - P(A&#39;).</p>

<p>\(P(A)+P\left(A^{\prime}\right)=1\)</p>

<p><strong>3. Conditional Rule</strong></p>

<p>When event A is already known to have occurred and probability of event B is desired, then P(B, given A)=P(A and B)P(A, given B). It can be vica versa in case of event B.<br />
\( \mathrm{P}(\mathrm{B} \mid \mathrm{A})=\mathrm{P}(\mathrm{A} \cap \mathrm{B}) \mathrm{P}(\mathrm{A})\)</p>

<p><strong>4. Multiplication Rule</strong></p>

<p>Whenever an event is the intersection of two other events, that is, events A and B need to occur simultaneously. <span style="background-color:null;">Then </span>P(A and B)=P(A)&sdot;P(B)<span style="background-color:null;">.</span></p>

<p>\(\mathrm{P}(\mathrm{A} \cap \mathrm{B})=\mathrm{P}(\mathrm{A}) \cdot \mathrm{P}(\mathrm{B} \mid \mathrm{A})\)</p>
